---
id: [feature-id]
title: [feature-name]
author: [architect]
description: "This document defines the implementation plan for the {feature-name} feature for engineers. The document is generated by Catalyst AI and reviewed by the feature architect."
dependencies:
  - [list-of-dependent-feature-ids]
---

<!-- markdownlint-disable single-title -->

# Implementation Plan: {feature-name}

> [CRITICAL INSTRUCTION]
> This implementation plan describes the full implementation of the feature **from scratch**, as if no code exists. Do NOT write this as an enhancement or modification to existing code. Use language like "Create", "Implement", "Build" - NOT "Modify", "Add to", "Update".

**Spec**: [Feature spec](./spec.md)

---

## Summary

> [INSTRUCTIONS]
> One concise paragraph (3-5 sentences) that combines:
>
> - What the feature does (from spec.md)
> - How it will be implemented (high-level technical approach)
> - What it enables (user/system benefit)
>
> This summary should be readable by both engineers and architects. Avoid implementation details - save those for "Implementation Approach" section.
>
> **Design rationale**: Reference `research.md` for detailed analysis of alternatives, decisions, and tradeoffs. Do NOT duplicate research findings here.

---

## Technical Context

This feature implementation plan extends the technical architecture defined in `.xe/architecture.md`.

**Feature-specific technical details:**

> [INSTRUCTIONS]
> Include essential technical details AI needs during code generation. Focus on feature-specific constraints and targets - not system-wide architecture. Use bullet points with bold labels:
>
> - **Primary Components**: [main functions/classes/modules this feature introduces]
> - **Data Structures**: [key data formats, schemas, types]
> - **Dependencies**: [other features/libraries this depends on]
> - **Configuration**: [config files, settings, environment variables, defaults]
> - **Performance Goals**: [specific measurable targets: <100ms, >1000 req/s, <50MB memory]
> - **Testing Framework**: [test framework and coverage target if different from system default]
> - **Key Constraints**: [feature-specific limits, security requirements, offline requirements]
>
> Include essentials from `.xe/architecture.md` that AI needs for implementation (testing framework, language version, key patterns). Do NOT duplicate the entire architecture document.

---

## Project Structure

> [INSTRUCTIONS]
> List ONLY the files this feature will create during implementation. Show file path and one-line purpose for each file. Format: One line per file with comment explaining what it implements.
>
> Technology-specific examples:
>
> **Backend API (Python/FastAPI):**
>
> ```
> src/api/routes/tasks.py              # Task CRUD API endpoints
> src/models/task.py                   # Task entity model with validation
> src/services/task_service.py         # Business logic for task operations
> tests/unit/test_task_model.py        # Task model unit tests
> tests/integration/test_tasks_api.py  # Task API integration tests
> ```
>
> **Frontend (React/TypeScript):**
>
> ```
> src/components/TaskList.tsx          # Task list display component
> src/hooks/useTasks.ts                # Task data fetching hook
> src/types/task.ts                    # Task type definitions
> src/api/tasks.ts                     # Task API client functions
> tests/components/TaskList.test.tsx   # Component tests
> ```
>
> **Mobile (Swift/iOS):**
>
> ```
> Sources/Models/Task.swift            # Task data model
> Sources/Services/TaskService.swift   # Task API service
> Sources/Views/TaskListView.swift     # Task list UI view
> Tests/TaskTests.swift                # Unit tests
> Tests/TaskServiceTests.swift         # Service integration tests
> ```
>
> **Library/CLI (Go):**
>
> ```
> internal/task/task.go                # Task type and operations
> internal/task/repository.go          # Task persistence layer
> cmd/task/list.go                     # CLI list command
> internal/task/task_test.go           # Unit tests
> internal/task/repository_test.go     # Integration tests
> ```

---

## Data Model

**Entities owned by this feature:**

> [INSTRUCTIONS]
> **ALWAYS document entities inline here** - AI needs this context when reading algorithms. For each entity, provide:
>
> - Entity name and one-sentence purpose
> - Key fields with types
> - Relationships to other entities (if applicable)
>
> Only create separate `data-model.md` if entities are complex (3+ entities with state machines/complex validation). If created, note: "Detailed schemas with validation rules: See data-model.md"
>
> Technology-specific examples:
>
> **TypeScript:**
>
> - **Task**: Represents a user task with priority and completion tracking
>   - `id`: string (UUID)
>   - `title`: string (max 200 chars)
>   - `status`: 'pending' | 'in_progress' | 'completed'
>   - `priority`: number (1-10)
>   - `assignedTo`: User (relationship)
>
> **Python:**
>
> - **TaskScoreDetails**: Score breakdown showing individual scoring components
>   - `emoji_contributions`: List[ContributionDict] (category, emoji, value)
>   - `project_bonus`: Decimal
>   - `placement_bonus`: Decimal
>   - `calculated_total`: Decimal
>
> **Swift:**
>
> - **TaskViewModel**: View model for task display logic
>   - `task`: Task (model reference)
>   - `isSelected`: Bool
>   - `formattedDueDate`: String (computed property)
>
> **SQL Schema:**
>
> - **tasks table**: Stores task records with metadata
>   - `id`: UUID PRIMARY KEY
>   - `title`: VARCHAR(200) NOT NULL
>   - `status_id`: INT FOREIGN KEY â†’ task_statuses
>   - `created_at`: TIMESTAMP DEFAULT NOW()

**Entities from other features:**

> [INSTRUCTIONS]
> List entities this feature CONSUMES but does not own. Include source feature name for reference.
>
> Example:
>
> - **User**: User account data (from auth feature)
> - **Project**: Project metadata (from project-management feature)

---

## Contracts

> [INSTRUCTIONS]
> **ALWAYS document contracts inline here** - AI needs this during code generation. Define function signatures or API endpoints depending on feature type. Use the tech-agnostic format below for consistency.

### [Function/Endpoint/Class Name]

**Signature:**

```
[Complete function/method/endpoint declaration in target language syntax]
```

**Purpose:** [One sentence describing what this does]

**Parameters:**

- `param1` ([type]): [Description]
- `param2` ([type], optional): [Description with default value if applicable]

**Returns:** [Return type and description]

**Errors/Exceptions:** [What can fail and why, if applicable]

**Examples:**

```
[Basic usage example showing minimal parameters]
```

```
[Advanced usage example with optional parameters]
```

> [NOTE FOR AI]
> For REST APIs: Also generate OpenAPI schema in `.xe/specs/{feature-id}/contracts/api.yaml` and reference here: "Full API specification: See contracts/api.yaml"
>
> For GraphQL APIs: Generate schema in `.xe/specs/{feature-id}/contracts/schema.graphql` and reference here: "Full GraphQL schema: See contracts/schema.graphql"

---

## Implementation Approach

> [INSTRUCTIONS]
> This is the CORE section - describe HOW to build the feature from scratch.
>
> **Structure:** Use H3 subsections (### 1., ### 2., etc.) for 3-8 implementation concerns.
> Only use multiple H2 sections if feature has distinct phases or 8+ orthogonal concerns.
>
> **Suggested subsections:**
>
> 1. **Data Structures** - Input/output formats with code examples
> 2. **Core Algorithms** - Step-by-step logic with numbered lists
> 3. **Integration Points** - Dependencies and consumers
> 4. **Error Handling** - Validation, edge cases, failure modes
> 5. **Performance Considerations** - Optimization strategies
> 6. **Testing Strategy** - Unit/integration/performance approaches
>
> For algorithms, use **numbered steps** showing execution flow.
> Use pseudocode or actual language syntax for complex logic.
> Reference `research.md` for design rationale - don't duplicate here.

### 1. Data Structures

> [INSTRUCTIONS]
> Show input/output formats with concrete examples. Use language-appropriate syntax (JSON for APIs, class definitions for OOP, type definitions for FP).

**Example (API JSON):**

**Input: Task Creation Request**

```json
{
  "title": "Fix login bug",
  "priority": 8,
  "emojis": {
    "status": ["ðŸš§"],
    "effort": ["ðŸŸ¢"]
  },
  "assignedTo": "user-123"
}
```

**Output: Task Score Response**

```json
{
  "score": 16.2,
  "breakdown": {
    "emojiContributions": [
      { "category": "status", "emoji": "ðŸš§", "value": 8 },
      { "category": "effort", "emoji": "ðŸŸ¢", "value": 5 }
    ],
    "projectBonus": 1.0,
    "placementBonus": 0.2
  }
}
```

### 2. Core Algorithms

> [INSTRUCTIONS]
> Break down main algorithm into numbered steps showing execution order.
> Be specific about logic, conditions, loops, transformations.

**Example: Task Scoring Algorithm**

1. **Load Configuration**:
   - Read emoji weights from configuration system
   - Apply defaults if weights not configured
   - Cache weights for performance

2. **Aggregate Emoji Values**:
   - Traverse task hierarchy from leaf to root
   - For single-value categories (status, effort): Select highest-weighted emoji
   - For multi-value categories (priority, tags): Combine all unique emojis
   - Sum weighted values across all categories
   - Result: Base emoji score (decimal)

3. **Calculate Bonuses**:
   - Project bonus: Find project in context array, apply priority multiplier
   - Placement bonus: If in active section, calculate `(total_items - position) / 10`
   - Default bonuses to 0 if not applicable

4. **Compute Total Score**:
   - Total = emoji_score + project_bonus + placement_bonus
   - Round to 1 decimal place for consistency

5. **Optional Breakdown Generation**:
   - If breakdown requested, create structured object with:
     - Individual emoji contributions (category, symbol, value)
     - Project and placement bonuses
     - Calculated total for validation
   - Return score with breakdown or score alone based on request

### 3. Integration Points

**Consumed by:**

- stack-summary feature: Calls scoring with breakdown for display
- task-filtering feature: Uses scores for priority sorting

**Depends on:**

- config-management feature: Provides emoji weight configuration
- project-files feature: Supplies task and project data

### 4. Error Handling

- Missing emoji categories: Default to zero contribution (graceful degradation)
- Invalid configuration: Use hardcoded defaults, log warning
- Null/empty task data: Return score of 0, do not throw
- Breakdown mismatch: Log validation warning if calculated total â‰  actual score

### 5. Performance Considerations

- Cache emoji weights (reload only on configuration changes)
- Minimize data structure traversals (single-pass aggregation)
- Use efficient data structures (hash maps for O(1) lookups)
- Profile with representative data (target: <1ms per task, <100ms for 1000 tasks)

### 6. Testing Strategy

**Unit Tests:**

- Emoji aggregation (single-value vs multi-value categories)
- Bonus calculations (project priority, placement position)
- Edge cases (missing data, zero scores, null inputs)
- Breakdown generation (structure, validation, zero-value handling)

**Integration Tests:**

- End-to-end scoring with real task hierarchies
- Configuration loading and caching
- Consumer integration (stack-summary, task-filtering)

**Performance Tests:**

- Benchmark individual scoring <1ms
- Benchmark batch scoring (1000 tasks) <100ms
- Memory usage validation

**Coverage Target:** >90% code coverage

---

## Usage Examples

> [INSTRUCTIONS]
> Show how to USE this feature after it's built (not migration from old code).
>
> Provide 2-3 practical examples:
>
> 1. Basic usage (minimal parameters)
> 2. Advanced usage (optional parameters)
> 3. Common integration pattern
>
> Use actual code syntax for the target technology.
> This validates design makes sense and helps AI generate integration code.

**Basic usage (TypeScript):**

```typescript
const score = await taskService.calculateScore(task, projects)
console.log(score) // 16.2
```

**With breakdown (Python):**

```python
result = task_service.get_task_score(task, projects, include_breakdown=True)
print(f"Score: {result['score']}")
print(f"Breakdown: {result['breakdown']}")
# Output: Score: 16.2, Breakdown: {...}
```

**Integration pattern (Swift):**

```swift
// In TaskListViewModel, calculating scores for display
func loadTasks() async {
    let tasks = await taskRepository.fetchAll()
    let projects = await projectRepository.fetchAll()

    self.scoredTasks = tasks.map { task in
        let result = taskScorer.calculateScore(
            for: task,
            projects: projects,
            includeBreakdown: true
        )
        return ScoredTask(task: task, score: result.value, breakdown: result.breakdown)
    }
}
```

**REST API consumption (JavaScript/Fetch):**

```javascript
// Get task with score breakdown
const response = await fetch("/api/v1/tasks/123?includeScore=true")
const data = await response.json()

console.log(data.task.score) // 16.2
console.log(data.task.breakdown) // { emojiContributions: [...], ... }
```
